{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zYnznVb_plTr",
        "hNZOlud_dkLX",
        "PrtfgQ5-sYtv",
        "bkZ5EVLrCy_W"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leticiasdd/Proj_aplicado_III/blob/main/Projeto_aplicado_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**RECOMENDAÇÃO DE LIVROS COM BASE NA PREFERÊNCIA CINEMATOGRÁFICA DO USUÁRIO**\n",
        "\n",
        "\n",
        "Bruno Luigi dos Santos Tobias | RA 10423789\n",
        "\n",
        "Letícia Serrano | RA 10415844\n",
        "\n",
        "Lucas Vaz | RA 10424623\n",
        "\n",
        "Lorena Vaz Cord | RA 10424700"
      ],
      "metadata": {
        "id": "0bey0BKaMzlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Datasets\n",
        "\n",
        "###Livros\n",
        "- https://cseweb.ucsd.edu/~jmcauley/datasets/goodreads.html\n",
        "- Baixar o arquivo: Detailed book graph (~2gb, about 2.3m books): goodreads_books.json.gz\n",
        "\n",
        "###Filmes\n",
        "- https://www.kaggle.com/datasets/gsimonx37/letterboxd?select=movies.csv\n",
        "- Baixar o arquivo: movies.csv\n",
        "\n",
        "###Instruções para execução do código:\n",
        "- Os datasets originais devem estar armazenados no Google Drive.\n",
        "- O caminho para os arquivos deve ser: Projeto aplicado 3/datasets/"
      ],
      "metadata": {
        "id": "_6fCoi_io42s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conexão com o Google Drive\n",
        "\n",
        "Esse metodo não funciona com arquivos compartilhados, é preciso ter uma cópia dos arquivos na pasta correta do Google Drive."
      ],
      "metadata": {
        "id": "zYnznVb_plTr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_Nw58BTkmPw",
        "outputId": "a67b6033-62c2-4b8a-ae82-485b953c6f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Montar o drive do Google\n",
        "# Após rodar esse código, ele pedirá autorização para acessar o Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir caminho para o dataset\n",
        "DIR = '/content/drive/MyDrive/Projeto aplicado 3/datasets/'"
      ],
      "metadata": {
        "id": "FHFL_ylImzkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importação das bibliotecas"
      ],
      "metadata": {
        "id": "hNZOlud_dkLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas\n",
        "import gzip\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "S5q9-B7CdpXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importação e pré processamento do dataset de livros"
      ],
      "metadata": {
        "id": "nhViCV7frBuK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Análise inicial do conteúdo do dataset de livros"
      ],
      "metadata": {
        "id": "ei65yr-KV32X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar as primeiras 10 linhas do JSON compactado\n",
        "def load_first_n(file_name, n=10):\n",
        "    data = []\n",
        "    with gzip.open(file_name) as fin:\n",
        "        for i, l in enumerate(fin):\n",
        "            if i >= n:\n",
        "                break\n",
        "            data.append(json.loads(l))\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Contar o numero de registros no JSON compactado\n",
        "def count_lines_in_gzip(file_path):\n",
        "    with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
        "        return sum(1 for _ in f)\n",
        "\n",
        "# Carrega as primeiras 10 linhas do arquivo\n",
        "file_path = '/content/drive/MyDrive/Projeto aplicado 3/datasets/goodreads_books.json.gz'\n",
        "df_sample = load_first_n(file_path, 10)"
      ],
      "metadata": {
        "id": "LsRo6siuWCO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantidade de registros e colunas\n",
        "# Esta etapa pode demorar alguns minutos para executar devido a quantidade de registros\n",
        "print(f\"\\nNúmero de registros: {count_lines_in_gzip(file_path)}\")\n",
        "print(f\"Número de colunas: {len(df_sample.columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8tYTADqXcN3",
        "outputId": "acd560d2-c809-49e5-e1d7-80f9b8190c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Número de registros: 2360655\n",
            "Número de colunas: 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de colunas no JSON compactado\n",
        "print(\"\\nColunas presentes no dataset de livros:\")\n",
        "for col in df_sample.columns:\n",
        "    print(f\" - {col}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXM-hxW3X1W8",
        "outputId": "5a8cf1db-fd6a-4228-810c-4507d064928a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Colunas presentes no dataset de livros:\n",
            " - isbn\n",
            " - text_reviews_count\n",
            " - series\n",
            " - country_code\n",
            " - language_code\n",
            " - popular_shelves\n",
            " - asin\n",
            " - is_ebook\n",
            " - average_rating\n",
            " - kindle_asin\n",
            " - similar_books\n",
            " - description\n",
            " - format\n",
            " - link\n",
            " - authors\n",
            " - publisher\n",
            " - num_pages\n",
            " - publication_day\n",
            " - isbn13\n",
            " - publication_month\n",
            " - edition_information\n",
            " - publication_year\n",
            " - url\n",
            " - image_url\n",
            " - book_id\n",
            " - ratings_count\n",
            " - work_id\n",
            " - title\n",
            " - title_without_series\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar as primeiras linhas\n",
        "print(\"Exemplo de registros:\")\n",
        "print(df_sample.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RubRwe2JX3QM",
        "outputId": "aa2c79f1-414b-49a2-f489-c65ca27a77c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplo de registros:\n",
            "         isbn text_reviews_count    series country_code language_code  \\\n",
            "0  0312853122                  1        []           US                 \n",
            "1  0743509986                  6        []           US                 \n",
            "2                              7  [189911]           US           eng   \n",
            "3  0743294297               3282        []           US           eng   \n",
            "4  0850308712                  5        []           US                 \n",
            "\n",
            "                                     popular_shelves        asin is_ebook  \\\n",
            "0  [{'count': '3', 'name': 'to-read'}, {'count': ...                false   \n",
            "1  [{'count': '2634', 'name': 'to-read'}, {'count...                false   \n",
            "2  [{'count': '58', 'name': 'to-read'}, {'count':...  B00071IKUY    false   \n",
            "3  [{'count': '7615', 'name': 'to-read'}, {'count...                false   \n",
            "4  [{'count': '32', 'name': 'to-read'}, {'count':...                false   \n",
            "\n",
            "  average_rating kindle_asin  ... publication_month edition_information  \\\n",
            "0           4.00              ...                 9                       \n",
            "1           3.23  B000FC0PBC  ...                10            Abridged   \n",
            "2           4.03              ...                     Book Club Edition   \n",
            "3           3.49  B002ENBLOK  ...                 7                       \n",
            "4           3.40              ...                                         \n",
            "\n",
            "  publication_year                                                url  \\\n",
            "0             1984  https://www.goodreads.com/book/show/5333265-w-...   \n",
            "1             2001  https://www.goodreads.com/book/show/1333909.Go...   \n",
            "2             1987  https://www.goodreads.com/book/show/7327624-th...   \n",
            "3             2009  https://www.goodreads.com/book/show/6066819-be...   \n",
            "4                   https://www.goodreads.com/book/show/287140.Run...   \n",
            "\n",
            "                                           image_url  book_id ratings_count  \\\n",
            "0  https://images.gr-assets.com/books/1310220028m...  5333265             3   \n",
            "1  https://s.gr-assets.com/assets/nophoto/book/11...  1333909            10   \n",
            "2  https://images.gr-assets.com/books/1304100136m...  7327624           140   \n",
            "3  https://s.gr-assets.com/assets/nophoto/book/11...  6066819         51184   \n",
            "4  https://images.gr-assets.com/books/1413219371m...   287140            15   \n",
            "\n",
            "   work_id                                              title  \\\n",
            "0  5400751                        W.C. Fields: A Life on Film   \n",
            "1  1323437                                        Good Harbor   \n",
            "2  8948723  The Unschooled Wizard (Sun Wolf and Starhawk, ...   \n",
            "3  6243154                               Best Friends Forever   \n",
            "4   278577  Runic Astrology: Starcraft and Timekeeping in ...   \n",
            "\n",
            "                                title_without_series  \n",
            "0                        W.C. Fields: A Life on Film  \n",
            "1                                        Good Harbor  \n",
            "2  The Unschooled Wizard (Sun Wolf and Starhawk, ...  \n",
            "3                               Best Friends Forever  \n",
            "4  Runic Astrology: Starcraft and Timekeeping in ...  \n",
            "\n",
            "[5 rows x 29 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Definição das funções que serão utilizadas na preparação do dataset de livros"
      ],
      "metadata": {
        "id": "PrtfgQ5-sYtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Devido ao grande volume do dataset original de livros, optamos por realizar o pré-processamento em blocos (chunks). Isso evita problemas de memória durante a manipulação dos dados, permitindo processar o arquivo em partes gerenciáveis."
      ],
      "metadata": {
        "id": "7b7HNRSRQZEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para carregamento do arquivo em chunks (adaptada de https://cseweb.ucsd.edu/~jmcauley/datasets/goodreads.html)\n",
        "def load_data(file_name, chunk_size = 500):\n",
        "    count = 0\n",
        "    data = []\n",
        "    with gzip.open(file_name) as fin:\n",
        "        for l in fin:\n",
        "            d = json.loads(l)\n",
        "            count += 1\n",
        "            data.append(d)\n",
        "\n",
        "            if len(data) >= chunk_size:\n",
        "                yield data\n",
        "                data = []  # Limpa o buffer para o próximo chunk\n",
        "\n",
        "        if data:       # Retorna os dados restantes, se houver\n",
        "            yield data"
      ],
      "metadata": {
        "id": "R8jK6mbPrQEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As funções abaixo serão utilizadas para limpar e padronizar dados."
      ],
      "metadata": {
        "id": "YLZAY6bRthBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para tratar o campo do número de páginas do livro\n",
        "# Se a string estiver vazia (''), retona NaN, se não, converte a string em número inteiro\n",
        "def fix_pages(pages):\n",
        "    if pages == '':\n",
        "        return np.nan\n",
        "    else:\n",
        "        return int(pages)\n",
        "\n",
        "# Função para tratar o campo de nota de avaliação do livro\n",
        "# Se não conseguir converter o valor em número decimal, converte o valor para NaN\n",
        "def filter_rating(x):\n",
        "    try:\n",
        "        return float(x)\n",
        "    except ValueError:\n",
        "        return np.nan\n",
        "\n",
        "# Definição de parametros para filtrar o DataFrame de livros para deixar apenas os registros que são úteis para análise\n",
        "languages_list = ['eng','en-US','en-GB','en-CA','en']\n",
        "undesired_format = ['Audio CD','Audio','Audiobook','Audible Audio','MP3 CD','Audio Cassette','Overdrive Audiobook','online fanfiction','online fiction','online short story']\n",
        "rating_cutoff = 3.5\n",
        "min_lim_pages = 50\n",
        "desired_attributtes = ['description','publication_year','url','work_id','title']\n",
        "\n",
        "\n",
        "# Funções para limpar e filtrar o DataFrame de livros para deixar apenas os registros que são úteis para análise\n",
        "def treat_data(df, languages_list, undesired_format, rating_cutoff, min_lim_pages, desired_attributtes):\n",
        "    # Filtro de idioma\n",
        "    df = df[df['language_code'].isin(languages_list)]\n",
        "\n",
        "    # Filtro de formato da midia\n",
        "    df = df[-df['format'].isin(undesired_format)]\n",
        "\n",
        "    # Filtro de nota média de avaliação\n",
        "    df.loc[:, 'average_rating'] = df['average_rating'].apply(filter_rating)\n",
        "    df = df[df['average_rating'] >= rating_cutoff]\n",
        "\n",
        "    # Filtro de número mínimo de páginas\n",
        "    df.loc[:, 'num_pages'] = df['num_pages'].apply(fix_pages)\n",
        "    df = df[(df['num_pages'].isna()) | (df['num_pages'] > min_lim_pages)]\n",
        "\n",
        "    # Filtro para remover livros que não contém descrição\n",
        "    df = df[df['description'] != '']\n",
        "\n",
        "    # Filtro para remoção de livros com títulos duplicados\n",
        "    # Se houver dois ou mais livros com o mesmo título, ele remove os duplicados, mantendo o primeiro que aparecer no DataFrame\n",
        "    df = df.drop_duplicates(subset=['title'])\n",
        "\n",
        "    # Seleção de colunas utilizadas na análise\n",
        "    df = df[desired_attributtes]\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "sii0BAhksVFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduzimos o número de colunas para incluir apenas os atributos essenciais para a análise posterior, como título e descrição do livro. Essa redução simplifica o dataset, diminui o uso de memória.\n",
        "\n",
        "O tratamento também inclui filtros que removem registros com idiomas não relevantes, formatos de mídia indesejados, livros com nota de avaliação baixa, livros com pouco número de páginas e livros sem descrição.\n"
      ],
      "metadata": {
        "id": "Az0R8eVlb2CE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Processamento do dataset em blocos (chunks)\n",
        "\n",
        "O arquivo JSON é lido em blocos de 100.000 registros por vez. A cada bloco lido, são aplicados os filtros e as transformações definidos nas funções anteriores.\n",
        "\n",
        "Após o processamento, cada bloco é salvo separadamente como um arquivo no formato .csv."
      ],
      "metadata": {
        "id": "bkZ5EVLrCy_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta etapa pode demorar alguns minutos para executar devido a quantidade de registros\n",
        "# Pasta onde os blocos csv serão salvos\n",
        "output_dir = '/content/drive/MyDrive/Projeto aplicado 3/datasets/dataset_tratado_books/'\n",
        "\n",
        "# Cria a pasta se não existir\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Tratamento e exportação do dataset de livros em chunks\n",
        "ct = 0\n",
        "total_records = 0\n",
        "for chunk in load_data(os.path.join(DIR, 'goodreads_books.json.gz'), chunk_size=100000):\n",
        "    df_book_raw = pd.DataFrame(chunk)\n",
        "    df_book_raw = treat_data(df_book_raw, languages_list, undesired_format, rating_cutoff, min_lim_pages, desired_attributtes)\n",
        "    ct += 1\n",
        "    total_records += len(df_book_raw)\n",
        "    output_path = os.path.join(output_dir, f'chunk_{ct}.csv')\n",
        "    df_book_raw.to_csv(output_path, index=False)\n",
        "    print(f\"Chunk {ct} salvo com {len(df_book_raw)} registros.\")\n",
        "\n",
        "print(f\"\\nProcessamento finalizado. Total de registros processados: {total_records}\")"
      ],
      "metadata": {
        "id": "s7_lNlik3mdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5e4603-200b-4f10-a909-95321bc3e00a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1 salvo com 25666 registros.\n",
            "Chunk 2 salvo com 25840 registros.\n",
            "Chunk 3 salvo com 25798 registros.\n",
            "Chunk 4 salvo com 25225 registros.\n",
            "Chunk 5 salvo com 25292 registros.\n",
            "Chunk 6 salvo com 25460 registros.\n",
            "Chunk 7 salvo com 25216 registros.\n",
            "Chunk 8 salvo com 25493 registros.\n",
            "Chunk 9 salvo com 25298 registros.\n",
            "Chunk 10 salvo com 25351 registros.\n",
            "Chunk 11 salvo com 25509 registros.\n",
            "Chunk 12 salvo com 25516 registros.\n",
            "Chunk 13 salvo com 25868 registros.\n",
            "Chunk 14 salvo com 25921 registros.\n",
            "Chunk 15 salvo com 25623 registros.\n",
            "Chunk 16 salvo com 25664 registros.\n",
            "Chunk 17 salvo com 25386 registros.\n",
            "Chunk 18 salvo com 25521 registros.\n",
            "Chunk 19 salvo com 25322 registros.\n",
            "Chunk 20 salvo com 25475 registros.\n",
            "Chunk 21 salvo com 25257 registros.\n",
            "Chunk 22 salvo com 25408 registros.\n",
            "Chunk 23 salvo com 25448 registros.\n",
            "Chunk 24 salvo com 15352 registros.\n",
            "\n",
            "Processamento finalizado. Total de registros processados: 601909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optamos por salvar os arquivos em blocos pré-processados no formato CSV como uma etapa intermediária no fluxo de tratamento dos dados. Essa abordagem permite que o pré-processamento seja executado apenas uma vez, evitando a repetição de etapas onerosas.\n",
        "\n",
        "Além disso, caso ocorra alguma falha, interrupção ou necessidade de ajustes posteriores, é possível retomar o processo a partir dos arquivos já salvos, sem a necessidade de reprocessar o dataset bruto original."
      ],
      "metadata": {
        "id": "GUCna9RuRUtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importação e pré processamento do dataset de filmes"
      ],
      "metadata": {
        "id": "a1qGjfsNc_y6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Carregamento e análise inicial do conteúdo do dataset de filmes"
      ],
      "metadata": {
        "id": "EBbkC264dvc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho do arquivo\n",
        "movies_zip_path = os.path.join(DIR, 'movies.csv.zip')\n",
        "\n",
        "# Carregar o CSV diretamente do arquivo ZIP\n",
        "df_film_raw = pd.read_csv(movies_zip_path)\n",
        "print(f\"\\nProcessamento finalizado. Total de registros processados: {len(df_film_raw)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7-vnW6l7JD5",
        "outputId": "5ffb0a91-935f-49d5-efd2-d2c51e1c4c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processamento finalizado. Total de registros processados: 941597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantidade de registros e colunas\n",
        "print(f\"Número de registros: {len(df_film_raw)}\")\n",
        "print(f\"Número de colunas: {len(df_film_raw.columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-XltPqj7vJB",
        "outputId": "ac771683-3c89-4be2-e93e-676ca6b98b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de registros: 941597\n",
            "Número de colunas: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de colunas\n",
        "print(\"Colunas presentes no dataset de filmes:\")\n",
        "for col in df_film_raw.columns:\n",
        "    print(f\" - {col}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bzv4GeLH7ygr",
        "outputId": "3df874da-00ab-4d09-852e-e32a06b91ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colunas presentes no dataset de filmes:\n",
            " - id\n",
            " - name\n",
            " - date\n",
            " - tagline\n",
            " - description\n",
            " - minute\n",
            " - rating\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar as primeiras linhas\n",
        "print(df_film_raw.head())"
      ],
      "metadata": {
        "id": "grFYp3WsdFns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a69d12c-fa22-442e-ce53-6ae736c6b1eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id                               name    date  \\\n",
            "0  1000001                             Barbie  2023.0   \n",
            "1  1000002                           Parasite  2019.0   \n",
            "2  1000003  Everything Everywhere All at Once  2022.0   \n",
            "3  1000004                         Fight Club  1999.0   \n",
            "4  1000005                         La La Land  2016.0   \n",
            "\n",
            "                                            tagline  \\\n",
            "0                  She's everything. He's just Ken.   \n",
            "1                       Act like you own the place.   \n",
            "2  The universe is so much bigger than you realize.   \n",
            "3                           Mischief. Mayhem. Soap.   \n",
            "4                    Here's to the fools who dream.   \n",
            "\n",
            "                                         description  minute  rating  \n",
            "0  Barbie and Ken are having the time of their li...   114.0    3.86  \n",
            "1  All unemployed, Ki-taek's family takes peculia...   133.0    4.56  \n",
            "2  An aging Chinese immigrant is swept up in an i...   140.0    4.30  \n",
            "3  A ticking-time-bomb insomniac and a slippery s...   139.0    4.27  \n",
            "4  Mia, an aspiring actress, serves lattes to mov...   129.0    4.09  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar valores duplicados na coluna id\n",
        "sum(df_film_raw['id'].duplicated())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXAf5veP8UPZ",
        "outputId": "810c22a0-f710-4e5f-fdd8-a007f68010c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar valores ausentes em cada coluna\n",
        "print(\"Valores ausentes por coluna:\")\n",
        "print(df_film_raw.isna().sum())\n",
        "\n",
        "# Verificar o total de valores ausentes no DataFrame\n",
        "total_missing = df_film_raw.isna().sum().sum()\n",
        "print(f\"\\nTotal de valores ausentes no dataset: {total_missing}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKJKsvaABNNT",
        "outputId": "f1040882-d96a-4259-c893-dccd35bcd0df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores ausentes por coluna:\n",
            "id                  0\n",
            "name               10\n",
            "date            91913\n",
            "tagline        802210\n",
            "description    160812\n",
            "minute         181570\n",
            "rating         850598\n",
            "dtype: int64\n",
            "\n",
            "Total de valores ausentes no dataset: 2087113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preparação do dataset de filmes"
      ],
      "metadata": {
        "id": "qCO62U_t4M1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover registros de filmes sem nome\n",
        "df_film_raw.dropna(subset=['name'], inplace=True)\n",
        "\n",
        "# Remover registros de filmes sem descrição\n",
        "df_film_raw.dropna(subset=['description'], inplace=True)\n",
        "\n",
        "# Exibir quantidade de registros final\n",
        "print(f\"Total de registros no dataset: {len(df_film_raw)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e_e3rb98naP",
        "outputId": "86396bad-53d5-4cb9-f988-b3881e09a480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de registros no dataset: 780783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Durante a análise inicial do dataset de filmes, observamos a presença de registros com dados ausentes, como a identificação única de um filme depende tanto de seu nome quanto da sua data, optamos por priorizar os registros que contêm ambas as informações.\n",
        "\n",
        "Dessa forma, realizamos a ordenação do dataset de forma que, para cada conjunto de filmes com o mesmo nome, os registros com data de lançamento aparecessem primeiro. Em seguida, removemos os registros duplicados com base na coluna name, mantendo o primeiro registro de cada grupo."
      ],
      "metadata": {
        "id": "UMXqP-c8_8Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover filmes com nomes duplicados\n",
        "# Ordenar o DataFrame para garantir que os registros com data apareçam antes dos que não têm data\n",
        "df_film_raw = df_film_raw.sort_values(by=['name', 'date'], ascending=[True, False])\n",
        "\n",
        "# Criar uma coluna auxiliar para indicar se há data (True/False)\n",
        "df_film_raw['has_date'] = df_film_raw['date'].notna()\n",
        "\n",
        "# Remover registros duplicados mantendo o primeiro registro por nome, priorizando os que têm data\n",
        "df_film_raw = df_film_raw.drop_duplicates(subset=['name'], keep='first')\n",
        "\n",
        "# Remover a coluna auxiliar\n",
        "df_film_raw = df_film_raw.drop(columns=['has_date'])\n",
        "\n",
        "# Exibir quantidade de registros final\n",
        "print(f\"Total de registros no dataset após remover duplicados: {len(df_film_raw)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLnmjjcxDnQ2",
        "outputId": "e7c5e6d8-063e-4dbc-adad-f2cb6a763390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de registros no dataset após remover duplicados: 652839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleção de colunas utilizadas na análise\n",
        "df_film_raw = df_film_raw[['id', 'name', 'date', 'tagline', 'description']]"
      ],
      "metadata": {
        "id": "GS8VY3F1EmsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduzimos o número de colunas para incluir apenas os atributos essenciais para a análise posterior, como nome do filme e descrição."
      ],
      "metadata": {
        "id": "HeorZH9CbBJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Processamento do dataset de filmes\n",
        "\n",
        "Após a realização das etapas de limpeza e tratamento dos dados do dataset de filmes — incluindo a remoção de registros com campos essenciais ausentes, como nome e descrição, e a eliminação de duplicatas priorizando os registros mais completos — optamos por salvar o dataset tratado em formato CSV.\n",
        "\n",
        "Essa decisão segue o mesmo padrão adotado durante o processamento do dataset de livros e tem como principal objetivos padronizar o fluxo de trabalho."
      ],
      "metadata": {
        "id": "Cwi46b6ibQg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pasta onde o csv tratato será salvo\n",
        "output_dir_film = '/content/drive/MyDrive/Projeto aplicado 3/datasets/dataset_tratado_films'\n",
        "\n",
        "# Criar a pasta se não existir\n",
        "os.makedirs(output_dir_film, exist_ok=True)\n",
        "\n",
        "# Definição do nome do csv\n",
        "output_path_film = os.path.join(output_dir_film, 'films_treated.csv')\n",
        "\n",
        "# Exportar o DataFrame como CSV\n",
        "df_film_raw.to_csv(output_path_film, index=False)\n",
        "\n",
        "print(f\"\\nProcessamento finalizado. Total de registros processados: {len(df_film_raw)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmEGSI5CF9JK",
        "outputId": "6ca03663-903c-4ca0-aa5d-37762ef7d693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processamento finalizado. Total de registros processados: 652839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Carregamento dos dados tratatos"
      ],
      "metadata": {
        "id": "u4dkP043cSdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Unificação e carregamento dos blocos com os dados tratados de livros"
      ],
      "metadata": {
        "id": "gp9UQU0TS4UF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho para os chunks de livros no Google Drive\n",
        "books_dir = '/content/drive/MyDrive/Projeto aplicado 3/datasets/dataset_tratado_books/'\n",
        "\n",
        "# Lista os arquivos da pasta\n",
        "book_files = os.listdir(books_dir)\n",
        "\n",
        "# DataFrame vazio para acumular os dados\n",
        "df_book = pd.DataFrame()\n",
        "\n",
        "# Loop para carregar e concatenar os chunks\n",
        "for file in book_files:\n",
        "    if 'chunk' in file and file.endswith('.csv'):\n",
        "        file_path = os.path.join(books_dir, file)\n",
        "        df_chunk = pd.read_csv(file_path)\n",
        "        df_book = pd.concat([df_book, df_chunk], ignore_index=True)\n",
        "        print(f\"Carregado: {file} ({len(df_chunk)} registros)\")\n",
        "\n",
        "print(f\"\\nTotal de registros de livros: {len(df_book)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51VlXfgDK96_",
        "outputId": "0ab983bb-5c53-4730-b262-eb87897703c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregado: chunk_1.csv (25666 registros)\n",
            "Carregado: chunk_2.csv (25840 registros)\n",
            "Carregado: chunk_3.csv (25798 registros)\n",
            "Carregado: chunk_4.csv (25225 registros)\n",
            "Carregado: chunk_5.csv (25292 registros)\n",
            "Carregado: chunk_6.csv (25460 registros)\n",
            "Carregado: chunk_7.csv (25216 registros)\n",
            "Carregado: chunk_8.csv (25493 registros)\n",
            "Carregado: chunk_9.csv (25298 registros)\n",
            "Carregado: chunk_10.csv (25351 registros)\n",
            "Carregado: chunk_11.csv (25509 registros)\n",
            "Carregado: chunk_12.csv (25516 registros)\n",
            "Carregado: chunk_13.csv (25868 registros)\n",
            "Carregado: chunk_14.csv (25921 registros)\n",
            "Carregado: chunk_15.csv (25623 registros)\n",
            "Carregado: chunk_16.csv (25664 registros)\n",
            "Carregado: chunk_17.csv (25386 registros)\n",
            "Carregado: chunk_18.csv (25521 registros)\n",
            "Carregado: chunk_19.csv (25322 registros)\n",
            "Carregado: chunk_20.csv (25475 registros)\n",
            "Carregado: chunk_21.csv (25257 registros)\n",
            "Carregado: chunk_22.csv (25408 registros)\n",
            "Carregado: chunk_23.csv (25448 registros)\n",
            "Carregado: chunk_24.csv (15352 registros)\n",
            "\n",
            "Total de registros de livros: 601909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar as primeiras linhas\n",
        "print(df_book.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3p9e6LJTZKi",
        "outputId": "381f1575-c4b9-4909-cad0-ead876a001e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         description  publication_year  \\\n",
            "0  Omnibus book club edition containing the Ladie...            1987.0   \n",
            "1  What is Heaven really going to be like? What w...               NaN   \n",
            "2  A stunning and revealing examination of oil's ...               NaN   \n",
            "3  Number 30 in a series of literary pamphlets pu...            1887.0   \n",
            "4  Embrace the word of God with the inspirational...            2013.0   \n",
            "\n",
            "                                                 url   work_id  \\\n",
            "0  https://www.goodreads.com/book/show/7327624-th...   8948723   \n",
            "1   https://www.goodreads.com/book/show/89376.Heaven     86257   \n",
            "2  https://www.goodreads.com/book/show/6158967-cr...   6338156   \n",
            "3  https://www.goodreads.com/book/show/16037549-v...   5212748   \n",
            "4  https://www.goodreads.com/book/show/18628482-u...  26419472   \n",
            "\n",
            "                                               title  \n",
            "0  The Unschooled Wizard (Sun Wolf and Starhawk, ...  \n",
            "1                                             Heaven  \n",
            "2           Crude World: The Violent Twilight of Oil  \n",
            "3              Vision of Sir Launfal and Other Poems  \n",
            "4          Understand God's Word - Walk in the Truth  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Carregamento dos dados tratados de filmes"
      ],
      "metadata": {
        "id": "HQddD6q3S7nY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho do arquivo de filmes Google Drive\n",
        "file_path = '/content/drive/MyDrive/Projeto aplicado 3/datasets/dataset_tratado_films/films_treated.csv'\n",
        "\n",
        "# Carregar o CSV\n",
        "df_film = pd.read_csv(file_path)\n",
        "\n",
        "# Exibir quantidade de registros carregados\n",
        "print(f\"Total de registros carregados: {len(df_film)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M9ZqwDlS-vb",
        "outputId": "f1a933f1-6fe3-4acc-9fdd-9b0ae92bb5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de registros carregados: 652839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar as primeiras linhas\n",
        "print(df_film.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9Jew3TzT2Lb",
        "outputId": "d19fc961-f537-4732-ce5b-2df99ad45938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id                                   name    date  \\\n",
            "0  1516866                                      !  2023.0   \n",
            "1  1826456                   ! (Exclamation Mark)  2023.0   \n",
            "2  1771719  ! BONUS VIDEO ! - A Melee Combo Video  2023.0   \n",
            "3  1320487                          ! EXCLAMATION  1976.0   \n",
            "4  1392532                              ! [ai-ou]  1991.0   \n",
            "\n",
            "                    tagline  \\\n",
            "0                       NaN   \n",
            "1                       NaN   \n",
            "2                       NaN   \n",
            "3             ! EXCLAMATION   \n",
            "4  気づいてほしい･･･ [ai-ou] 心の叫び。   \n",
            "\n",
            "                                         description  minute  rating  \\\n",
            "0  Follows the rising panic of having something t...     3.0     NaN   \n",
            "1  An original short film that explores important...     4.0     NaN   \n",
            "2  Sequel to Annihilation Domination (Artistic en...     2.0     NaN   \n",
            "3  This short film tells a story in the form of a...    17.0     NaN   \n",
            "4  Three outsiders meet by chance and try to chas...   108.0     NaN   \n",
            "\n",
            "                                                tags  \n",
            "0  !  Follows the rising panic of having somethin...  \n",
            "1  ! (Exclamation Mark)  An original short film t...  \n",
            "2  ! BONUS VIDEO ! - A Melee Combo Video  Sequel ...  \n",
            "3  ! EXCLAMATION ! EXCLAMATION This short film te...  \n",
            "4  ! [ai-ou] 気づいてほしい･･･ [ai-ou] 心の叫び。 Three outsi...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Execução do modelo"
      ],
      "metadata": {
        "id": "lH67C6UJT9mK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para que o modelo de recomendação baseado em similaridade textual funcione de forma eficiente, é essencial que o vocabulário utilizado pelo vetorizar TF-IDF seja construído a partir de todo o conteúdo disponível. Isso garante que os termos presentes tanto nos livros quanto nos filmes sejam considerados de maneira unificada, possibilitando uma comparação justa entre os dois conjuntos.\n",
        "\n",
        "Nesta etapa, realizamos a concatenação dos principais atributos textuais dos livros e filmes em uma nova coluna chamada tags, unificando título, descrição e, no caso dos filmes, também o tagline. Em seguida, essas colunas são combinadas em uma única série (all_tags), que será usada para construir o vocabulário do TF-IDF.\n",
        "\n",
        "Dessa forma, o modelo consegue mapear relações entre obras com base em descrições semelhantes, mesmo que estejam em domínios diferentes (literatura e cinema)."
      ],
      "metadata": {
        "id": "UluwXDLIUClb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenando os atributos do dataset de livros\n",
        "df_book['tags'] = df_book['title'].fillna(\"\") + ' ' + df_book['description'].fillna(\"\")\n",
        "\n",
        "# Concatenando os atributos do dataset de filmes\n",
        "df_film['tags'] = df_film['name'].fillna(\"\") + ' ' + df_film['tagline'].fillna(\"\") + ' ' + df_film['description'].fillna(\"\")\n",
        "\n",
        "# Concatenar as colunas de tags de ambos os datasets\n",
        "all_tags = pd.concat([df_film['tags'], df_book['tags']], ignore_index=True)"
      ],
      "metadata": {
        "id": "BFlwIFE2UJOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com a série all_tags unificando as descrições de filmes e livros, iniciamos o processo de vetorização utilizando o modelo TF-IDF, uma técnica amplamente usada para representar textos numericamente com base na relevância de cada termo em relação ao corpus total.\n",
        "\n",
        "Primeiramente, instanciamos o TfidfVectorizer, que é responsável por transformar os textos em vetores numéricos. Utilizamos o parâmetro stop_words='english' para remover palavras comuns da língua inglesa que não agregam significado (como \"the\", \"and\", \"of\", etc.), reduzindo o ruído nos dados.\n",
        "\n",
        "Em seguida, ajustamos o vetorizador (fit) usando todo o conteúdo combinado de filmes e livros, garantindo que o vocabulário aprendido seja global e compartilhe a mesma base de termos. Isso é essencial para possibilitar a comparação entre obras de diferentes domínios no mesmo espaço vetorial.\n",
        "\n",
        "Após o ajuste, aplicamos a transformação (transform) separadamente nos conjuntos de filmes e livros. O resultado são dois conjuntos de vetores TF-IDF (film_tfidf e book_tfidf), que representam, de forma numérica, o conteúdo textual de cada item."
      ],
      "metadata": {
        "id": "92pZBOHPfs9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Essa etapa pode demorar alguns minutos\n",
        "# Criar e ajustar o vetorizador com todas as tags (de filmes e livros)\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "vectorizer.fit(all_tags)\n",
        "\n",
        "# Transformar cada dataset separadamente com o mesmo vocabulário treinado\n",
        "film_tfidf = vectorizer.transform(df_film['tags'])\n",
        "book_tfidf = vectorizer.transform(df_book['tags'])"
      ],
      "metadata": {
        "id": "Psf7r9glU3wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último, a função recomendation recebe o nome de um filme e retorna uma lista dos 10 livros mais similares a ele, com base na similaridade dos conteúdos textuais (usando TF-IDF e similaridade cosseno)."
      ],
      "metadata": {
        "id": "i0q3L4lMgKiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recomendation(film_title):\n",
        "    matches = df_film[df_film['name'].str.lower() == film_title.lower()]\n",
        "\n",
        "    if matches.empty:\n",
        "        return f\"Filme '{film_title}' não encontrado no dataset.\"\n",
        "\n",
        "    i_film = matches.index[0]\n",
        "    similaridades = cosine_similarity(film_tfidf[i_film], book_tfidf)\n",
        "    i_books = similaridades.argsort()[0][-10:][::-1]\n",
        "    return df_book.iloc[i_books][['title', 'url']]"
      ],
      "metadata": {
        "id": "NeKMBytcU-dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora podemos inserir o nome de um filme e recerber recomendações de livros similares."
      ],
      "metadata": {
        "id": "4fno3jmngdkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(recomendation('Conclave'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rddgh4TWjs8f",
        "outputId": "83adb895-6912-4f5f-bc6a-e477fe11c504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    title  \\\n",
            "255494  The Francis Miracle: Inside the Transformation...   \n",
            "251242                                      Peter’s Chair   \n",
            "412875                        The Making of the Pope 2005   \n",
            "540707  Strange Gods:  A Novel About Faith, Murder, Si...   \n",
            "140645  Pope to the Poor: The Life and Times of Pope F...   \n",
            "13955           What Has Happened to the Catholic Church?   \n",
            "211669           The Secret Cardinal (Nolan Kilkenny, #5)   \n",
            "159095                       Francis: Pope of a New World   \n",
            "167               The Possession of Lawrence Eugene Davis   \n",
            "516721  Render Unto Rome: The Secret Life of Money in ...   \n",
            "\n",
            "                                                      url  \n",
            "255494  https://www.goodreads.com/book/show/20898083-t...  \n",
            "251242  https://www.goodreads.com/book/show/7081044-pe...  \n",
            "412875  https://www.goodreads.com/book/show/1274463.Th...  \n",
            "540707  https://www.goodreads.com/book/show/28175644-s...  \n",
            "140645  https://www.goodreads.com/book/show/17715582-p...  \n",
            "13955   https://www.goodreads.com/book/show/19192828-w...  \n",
            "211669  https://www.goodreads.com/book/show/8390430-th...  \n",
            "159095  https://www.goodreads.com/book/show/17677799-f...  \n",
            "167     https://www.goodreads.com/book/show/25402549-t...  \n",
            "516721  https://www.goodreads.com/book/show/10000761-r...  \n"
          ]
        }
      ]
    }
  ]
}